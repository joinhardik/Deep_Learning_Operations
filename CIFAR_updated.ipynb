{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2CHkZkSmPwIY7+CH8df1X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9S3z5pRVb5xr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Activation, BatchNormalization, \\\n",
        "    MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n"
      ],
      "metadata": {
        "id": "zCWyQZ9ycFXK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "eKFXxEtdb88Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split():\n",
        "    X_train, y_train, X_test, y_test = load_dataset()\n",
        "    (X_train, X_valid) = X_train[5000:], X_train[:5000]\n",
        "    (y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
      ],
      "metadata": {
        "id": "jeBdlleycVs1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing():\n",
        "    X_train, X_test, X_valid, y_train, y_test, y_valid = data_split()\n",
        "    mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
        "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "    X_train = (X_train - mean) / (std + 1e-7)\n",
        "    X_valid = (X_valid - mean) / (std + 1e-7)\n",
        "    X_test = (X_test - mean) / (std + 1e-7)\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "    y_valid = to_categorical(y_valid, num_classes=num_classes)\n",
        "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
      ],
      "metadata": {
        "id": "eHWeGBLVcZL1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation():\n",
        "    X_train, X_test, X_valid, y_train, y_test, y_valid = preprocessing()\n",
        "    datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1, horizontal_flip=True,\n",
        "                                 vertical_flip=False)\n",
        "    datagen.fit(X_train)\n",
        "    return datagen, X_train, X_test, X_valid, y_train, y_test, y_valid"
      ],
      "metadata": {
        "id": "XFOmieXzcb36"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_creation():\n",
        "    datagen, X_train, X_test, X_valid, y_train, y_test, y_valid = augmentation()\n",
        "    base_hidden_layer = 32\n",
        "    weight_decay = 1e-4\n",
        "    model = Sequential()\n",
        "\n",
        "    # CONV-1\n",
        "    model.add(Conv2D(filters=base_hidden_layer, kernel_size=3, padding='same',\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     input_shape=X_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # CONV-2\n",
        "    model.add(Conv2D(filters=base_hidden_layer, kernel_size=3, padding='same',\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # POOL + Dropout\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # CONV-3\n",
        "    model.add(Conv2D(filters=base_hidden_layer * 2, kernel_size=3, padding='same',\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     input_shape=X_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # CONV-4\n",
        "    model.add(Conv2D(filters=base_hidden_layer * 2, kernel_size=3, padding='same',\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # POOL + Dropout\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # CONV-5\n",
        "    model.add(Conv2D(filters=base_hidden_layer * 4, kernel_size=3, padding='same',\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     input_shape=X_train.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # CONV-6\n",
        "    model.add(Conv2D(filters=base_hidden_layer * 4, kernel_size=3, padding='same',\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # POOL + Dropout\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # FC-7\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10., activation='softmax'))\n",
        "\n",
        "    return model, datagen, X_train, X_test, X_valid, y_train, y_test, y_valid\n"
      ],
      "metadata": {
        "id": "R8S_ohjrcfJw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    model, datagen, X_train, X_test, X_valid, y_train, y_test, y_valid = model_creation()\n",
        "    batch_size = 128\n",
        "    epochs = 10\n",
        "    # checkpointer = ModelCheckpoint(filepath='model.CIFAR_PART2.hdf5', verbose=2,\n",
        "    #                                save_best_only=True)\n",
        "    optimizer = optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "    history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        epochs=epochs, verbose=2, validation_data=(X_valid, y_valid))\n",
        "    return history, model, X_train, X_test, X_valid, y_train, y_test, y_valid"
      ],
      "metadata": {
        "id": "fyyKZkWfcjnG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict():\n",
        "\n",
        "    history, model, X_train, X_test, X_valid, y_train, y_test, y_valid = train_model()\n",
        "\n",
        "    score = model.evaluate(X_test, y_test, verbose=1, batch_size=128)\n",
        "    print(score[1] * 100)\n",
        "\n",
        "\n",
        "predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BGzDRhjcwaJ",
        "outputId": "c6d849e5-85be-4c40-939e-21cfeccc5093"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "351/351 - 21s - loss: 2.0146 - accuracy: 0.3878 - val_loss: 1.8708 - val_accuracy: 0.3804 - 21s/epoch - 59ms/step\n",
            "Epoch 2/10\n",
            "351/351 - 20s - loss: 1.4952 - accuracy: 0.5164 - val_loss: 1.3396 - val_accuracy: 0.5694 - 20s/epoch - 56ms/step\n",
            "Epoch 3/10\n",
            "351/351 - 19s - loss: 1.2501 - accuracy: 0.5939 - val_loss: 1.2066 - val_accuracy: 0.6176 - 19s/epoch - 55ms/step\n",
            "Epoch 4/10\n",
            "351/351 - 20s - loss: 1.1412 - accuracy: 0.6298 - val_loss: 0.9969 - val_accuracy: 0.6808 - 20s/epoch - 58ms/step\n",
            "Epoch 5/10\n",
            "351/351 - 19s - loss: 1.0379 - accuracy: 0.6619 - val_loss: 0.8906 - val_accuracy: 0.7156 - 19s/epoch - 55ms/step\n",
            "Epoch 6/10\n",
            "351/351 - 19s - loss: 0.9426 - accuracy: 0.6925 - val_loss: 0.8650 - val_accuracy: 0.7272 - 19s/epoch - 55ms/step\n",
            "Epoch 7/10\n",
            "351/351 - 19s - loss: 0.9000 - accuracy: 0.7088 - val_loss: 0.8236 - val_accuracy: 0.7522 - 19s/epoch - 55ms/step\n",
            "Epoch 8/10\n",
            "351/351 - 19s - loss: 0.8490 - accuracy: 0.7275 - val_loss: 0.7444 - val_accuracy: 0.7618 - 19s/epoch - 55ms/step\n",
            "Epoch 9/10\n",
            "351/351 - 19s - loss: 0.8206 - accuracy: 0.7364 - val_loss: 0.6715 - val_accuracy: 0.7922 - 19s/epoch - 55ms/step\n",
            "Epoch 10/10\n",
            "351/351 - 19s - loss: 0.7819 - accuracy: 0.7517 - val_loss: 0.7007 - val_accuracy: 0.7868 - 19s/epoch - 55ms/step\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.7430 - accuracy: 0.7759\n",
            "77.59000062942505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jyy8OKeAcyoL"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}